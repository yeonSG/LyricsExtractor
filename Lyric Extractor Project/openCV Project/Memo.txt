메인 알고리즘
 (1). 동영상 분석    : 타겟 파일을 열어 frame별 처리
    1. 가사 부분만 자름
    2. 이진화 (설명 참고1)
    3. 분석 : 프래임 별 흰점 개수, 이전 프래임 대비 흰점 변화량, 변화량에 대한 프로젝션 정보

 (2) 가사 추출
    1. 분석데이터로 가사 추출 (설명 참고2)

 (3) 시간 보정
    1. (2)가사 추출 단계에서 대략적인 Line들의 start-end 시간을 구한 것에서 이 단계에서는 더 정확한 frame 타이밍을 구함
    2. (참고 3)

 (3) 저장
    1. 분석데이터 저장 : Lyrics.txt



 참고1 이진화 알고리즘
    1. 이미지의 lyrics부분만 자름 (현제 고정값으로 자르는 중)
    2. lyrics의 패인팅 색(빨강, 파랑)에 해당하는 GBR, HSV 범위로 필터링 한 이미지를 다시한번 and 연산하여 최대한 노이즈를 적게함
    3. 해당 프레임에서 Adopted Thresold 알고리즘으로 뽑아낸 후 2번 이미지와 겹치 pixel에 floodfill하여 깔끔한 이미지 얻어냄

 참고2 가사 추출 알고리즘
    1. 흰색의 갯수가 상승하다 꺽이는 구간을 Peak라 하고 이부분을 분별해냄. (이 부분이 한 Line의 끝점이 됨)
    2. Peak의 시작점을 구해 Pair의 정보 묶음. (후에 가사 세부싱크를 얻기 위함)
    3. Peak부분의 Image를 얻어 이진화 후 OCR돌림
    4. 돌린 OCR 결과 취합

 참고3 가사 Line 타이밍 조정
    1. end frame을 Mask로 만들어 흰점의 최좌측, 최우측 x 좌표 구함(기준으로 함)
    2. start-end에 있는 frame들을 이진화함
    3. 이진화 된 이미지의 흰점 개수와 이전프래임과 달라지는 흰점의 위치 평균을 구함
    4. 해당 평균점이 Mask 기준으로 몇퍼센트 안에 들어가는지 파악 (가장 높은 퍼센테이지를 갖는 곳이 끝점, whiteCount가 0이 나오는 부분이 시작점)



    
    2020.01.16 앞으로의 프로젝트 방향 
    회의 내용
     - GUI처리는 최후반
     - 시간 걸리는 것 상관없음
     - 영문은 띄어쓰기마다 , 한글은 글자마다 싱크시간 필요
     - 

     개발해야 할 것
     - ROI(자막영역) 고정 값이 아닌 얻어진 값



     ---------------할것----------------
     1. 라인따는 알고리즘 수정 (더 정확한 버전)
        :: videoAnalization1()

     2. * 워드 단위로 시간 뽑아내기
        2-1. Line측정에 사용된 mask이미지로 x축 프로잭션 진행
        2-2. 시작x~끝x 사이에 빈 픽샐이 약 10개정도 있는 부분을 Separation으로 함
        2-3. word calibration 진행
        2-4. 저장

     3. 클래스 구조 수정
        .

     4. OCR 결과 개선
        :: 


     5. 관심영역 설정하는 코드 추가
        - 동적 관심범위 ()
        - how?
        - whiteCount 범위 크개잡아서 peak 뽑은 후
        - 해당 



    * 정의
        - 라인의 시작 frame : 색칠이 시작된 frame
        - 라인의 끝 frame   : 색칠이 완료된 frame
        ex)
         frame1
         frame2 -> 색칠 시작됨
         frame3
         frame4 -> 색칠 완료됨
         frame4
         ==> LineX의 (start, end) => (2, 4);

    * 테스트 영상 정보
    Movie.mp4(1280x720)
     - 태국어
     - 0~27Lines
    Movie1.mp4           
     - 태국어, 영어
     - 0~62Lines

    40009.mp4(352x288, Movie2.mp4)
     - 태국어
     - 0~66Lines
    40011.mp4(Movie3.mp4)   
     - 태국어, 영어
     - 0~46Lines
    40006.mp4
     - 태국어
     - 0~43Lines
    40003.mp4
     - 태국어(그림자형 폰트)
     - 0~60Lines

     gramy_vol8_6.mp4
     - 태국어(빨, 파 존재)
     - 0~79Lines
     gramy_vol8_4.mp4
     - 태국어(태두리에 검정 없는 폰트)
     - 0~52Lines


    할것
     - 기능 구현(xml형식 데이터)
     - 디버깅
     - 로깅
        : 로깅 재구현

     - UI 구성 : 
        1. 입력 : 파일 1개 or Directory 
        exam :  lyricExtractor.exe  [인자1]
                인자1 : 파일 or 폴더
                   - 파일이면 해당 파일만 분석
                   - 폴더면 해당 폴더 내부의 모든 파일 분석

    

    어떻게 하면 완성도를 높일 수 있을까..?
    - 로깅 재구현
    - 폴더가 중복된다면 


*프로그램 흐름
1. 영상 frame별 흰점 개수 Count
    - input : 영상
    - output: 영상의 frame별 White Pixcel Count
    : 가사 색칠된 픽샐의 개수 Count (색칠된것은 검-흰-빨(파) 의 배열이 존재하는 곳에서 흰색 지점을 말함 )

2. Peak 판별
    - input : 영상의 frame별 White Pixcel Count
    - output: 판별된 Peak의 frame 
    : 이상적으로 추출된 Peak는 Line의 끝점 frame이 됨.

3. Peak에서 Line 판별
    - input : 판별된 Peak의 frame, frame별 White Pixcel Count
    - output: 대략적인 Line의 start-end frame

4. Line 중 유효한 라인을 걸러내고 정확한 start-end frame을 잡아냄
    - input : 대략적인 Line의 start-end frame, 영상
    - output: 유효한 라인의 정확한 start-end frame, 해당 라인의 OCR 입력 이미지 (글자 흑백으로 이루어진 이미지)
    : python코드의 ML 아웃풋 사용해 mask image를 사용함.

5. 확정된 라인의 text를 얻음
    - input : 유효한 라인의 정확한 start-end frame, 해당 라인의 OCR 입력 이미지 (글자 흑백으로 이루어진 이미지)
    - output: 라인의 OCR output인 text, "Lyric.txt"
    : 글자의 흑백 이미지인 mask image를 저장한 후 각각을 OCR 입력으로 넣어 text를 얻어냄

6. OCR의 결과와 mask image를 비교해 워드 단위의 시간을 뽑아냄
    - input : 라인의 OCR output text, 라인의 start-end 정보, 라인의 mask image
    - output: 라인의 word 개수와 word별 start-end frame, "Lyrics_withWord.txt"
    
*예상 문제점
1. 예상치 못한 영상의 Lyric 스타일
    - 현 구현상태의 1단계에서 흰점 개수를 count할 때 사용되는 알고리즘에 벗어나는 입력이 들어 올 경우 알아채지 못함. (EX. grammy_vol8_4.mp4)
    - 이 문제가 발생했을 때 고칠 수 있는 부분은 뭘까?
        : 일단 1번 whiteCount 하